[
{
	"uri": "http://localhost:1313/overview/goal/",
	"title": "Objectif",
	"tags": [],
	"description": "",
	"content": "Your goal will be to TODO\n"
},
{
	"uri": "http://localhost:1313/overview/",
	"title": "Presentation",
	"tags": [],
	"description": "",
	"content": "Chapter 1 Presentation Welcome to this lab where TODO\n"
},
{
	"uri": "http://localhost:1313/overview/architecture/",
	"title": "Architecture",
	"tags": [],
	"description": "",
	"content": "Architecture TODO\n"
},
{
	"uri": "http://localhost:1313/development/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "1. Introduction The aim of this part is to familiarise you with the different microservices in the Crazy Train application. You will modify the code of several Quarkus, Python and Nodejs projects, understand how they interact and test the application as a whole.\nThe image below describes the overall operation\nBelow is a description of each service:\nCapture and process image (projectt capture-app): This is a Quarkus service that allows you to start, test and stop video capture. It exposes RESTful endpoints that can be called by other services or clients to control video capture.\nPredict command (project intelligent-train): This service is responsible for analysing the data from the captured video. It uses machine learning techniques to interpret the video data and provide information based on this analysis.\nPost process image (project train-ceq-app): is an event management service that receives information from Intelligent Train and other services, and triggers appropriate actions. For example, if the Intelligent Train detects an obstacle on the track, the service triggers an event to stop the train.\nControl Train (project train-controler): As its name suggests, this service is responsible for controlling the train itself. It would receive commands from services such as train-ceq and perform actions on the train, such as starting, stopping, changing speed, etc.\nMonitoring (project monitoring-app): This service is responsible for monitoring the entire system. It would collect data from all the other services, such as events triggered, actions performed, train status, etc., and provide an overview of the state of the system. It could also provide alerts or notifications in the event of problems being detected.\nEach service is independent and communicates with the others asynchronously (MQTT/Kafka). This allows great flexibility and scalability, as each service can be developed, deployed and scaled independently of the others.\n2. Your lab environment You are going to use OpenShift Dev Spaces. OpenShift Dev Spaces uses Kubernetes and containers to provide a consistent, secure, and zero-configuration development environment, accessible from a browser window.\nUse the following link to generate your Openshift Dev Space environment :\nLogin in with your OpenShift credentials (userX/yourpassword). If this is the first time you access Dev Spaces, you have to authorize Dev Spaces to access your account. In the Authorize Access window click on Allow selected permissions.\nThis opens the workspace, which will look pretty familiar if you are used to work with VS Code. Before opening the workspace, a pop-up might appear asking if you trust the contents of the workspace. Click Yes, I trust the authors to continue.\nThe workspace contains all the resources you are going to use during the workshop. In the project explorer on the left of the workspace, navigate to the rivieradev-app folder and look at the different projects.\n"
},
{
	"uri": "http://localhost:1313/ai/",
	"title": "Artificial Intelligence (1h)",
	"tags": [],
	"description": "",
	"content": "Part 2 Artificial Intelligence "
},
{
	"uri": "http://localhost:1313/development/capture-app/",
	"title": "Capture and pre process image",
	"tags": [],
	"description": "",
	"content": "capture-app is built using Quarkus, a full Java framework native to Kubernetes, designed for Java Virtual Machines (JVMs) and native compilation, optimising Java specifically for containers and enabling it to become an effective platform for serverless, cloud and Kubernetes environments.\nThe main functionality of the capture-app microservice is to control video capture. It offers the ability to start and stop video streaming, via exposed RESTful endpoints. These endpoints can be called from any http client (such as a web browser or a curl command in a terminal).\nIn the capture-app project, you will add two new properties to the application.properties file and modify the ScheduledCapture.java class to load these properties.\nModify the configuration file: Open the configuration file for your application. This is the file named src/main/application.properties. Add the following properties: Add the two new properties: %dev.capture.mock=true %dev.capture.videoPath=/projects/rivieradev-app/capture-app/src/main/resources/videos/track-christmas-tree.avi Save your changes.\nOpen the file src/main/java/org/redhat/demo/crazytrain/captureimage/ScheduledCapture.java.\nAdd the @ConfigProperty annotations to load the new properties. Add these lines to the top of the class, just below the class declaration:\n@ConfigProperty(name = \u0026#34;capture.mock\u0026#34;) boolean mock; @ConfigProperty(name = \u0026#34;capture.videoPath\u0026#34;) String videoPath; Checking the code The src/main/java/com/train/capture/app/ScheduledCapture.java class should look like this:\npackage org.redhat.demo.crazytrain.captureimage; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.event.Observes; import jakarta.inject.Inject; import jakarta.ws.rs.GET; import jakarta.ws.rs.POST; import jakarta.ws.rs.Path; import jakarta.ws.rs.core.Response; import jakarta.ws.rs.core.Response.ResponseBuilder; import java.util.ArrayList; import java.util.List; import org.eclipse.microprofile.config.inject.ConfigProperty; import org.eclipse.paho.client.mqttv3.MqttException; import org.jboss.logging.Logger; import org.opencv.core.Mat; import org.opencv.core.Size; import org.opencv.imgproc.Imgproc; import org.opencv.videoio.VideoCapture; import org.opencv.videoio.Videoio; import org.redhat.demo.crazytrain.mqtt.MqttPublisher; import org.redhat.demo.crazytrain.util.Util; import io.quarkus.runtime.StartupEvent; import io.quarkus.scheduler.Scheduled; import io.vertx.mutiny.core.Vertx; /** * ScheduledCapture is a service that captures images from a camera using the OpenCV library */ @ApplicationScoped @Path(\u0026#34;/capture\u0026#34;) public class ScheduledCapture { private VideoCapture camera; @Inject ImageCaptureService imageCaptureService; @Inject ImageService imageService; @Inject Vertx vertx; // interval in milliseconds @ConfigProperty(name = \u0026#34;capture.interval\u0026#34;) int interval; // tmpFolder is the folder where the images are saved @ConfigProperty(name = \u0026#34;capture.tmpFolder\u0026#34;) String tmpFolder; // broker is the MQTT broker @ConfigProperty(name = \u0026#34;capture.brokerMqtt\u0026#34;) String broker; // topic is the MQTT topic @ConfigProperty(name = \u0026#34;capture.topic\u0026#34;) String topic; // nbImgSec is the number of images captured every second @ConfigProperty(name = \u0026#34;capture.periodicCapture\u0026#34;) int periodicCapture; @ConfigProperty(name = \u0026#34;capture.saveImage\u0026#34;) boolean saveImage; @ConfigProperty(name = \u0026#34;capture.videoDeviceIndex\u0026#34;) int videoDeviceIndex; @ConfigProperty(name = \u0026#34;capture.mock\u0026#34;) boolean mock; @ConfigProperty(name = \u0026#34;capture.videoPath\u0026#34;) String videoPath; @ConfigProperty(name = \u0026#34;capture.videoPeriodicCapture\u0026#34;) int videoPeriodicCapture; MqttPublisher mqttPublisher = null; private Long timerId; private volatile boolean stopRequested = false; private Thread testThread; private static final Logger LOGGER = Logger.getLogger(ScheduledCapture.class); Util util = null; // Start the camera when the application starts and set the resolution void onStart(@Observes StartupEvent ev) { Logger.getLogger(ScheduledCapture.class).info(\u0026#34;The application is starting...\u0026#34;); if(!mock){ camera = new VideoCapture(videoDeviceIndex); camera.set(Videoio.CAP_PROP_FRAME_WIDTH, 640); // Max resolution for Logitech C505 camera.set(Videoio.CAP_PROP_FRAME_HEIGHT, 480); // Max resolution for Logitech C505 //camera.set(Videoio.CAP_PROP_AUTOFOCUS, 0); // Try to disable autofocus //camera.set(Videoio.CAP_PROP_FOCUS, 255); // Try to disable autofocus camera.set(Videoio.CAP_PROP_EXPOSURE, 15); // Try to set exposure } util = new Util(); mqttPublisher = new MqttPublisher(broker.trim(), topic.trim()); } void readVideo(String videoPath) { VideoCapture capture = new VideoCapture(videoPath); if (!capture.isOpened()) { throw new IllegalArgumentException(\u0026#34;Video file not found at \u0026#34; + videoPath); } double fps = capture.get(Videoio.CAP_PROP_FPS); int frameSkip = (int) (fps/8); int count = 0; Mat frame = new Mat(); while (!stopRequested) { // Continue reading the video until a stop request is received while (capture.read(frame)) { if (count % frameSkip == 0) { // Publish the image to the MQTT broker long timestamp = System.currentTimeMillis(); if(util != null) { long start2 = System.nanoTime(); String jsonMessage = util.matToJson(frame, timestamp); long end2 = System.nanoTime(); LOGGER.debugf(\u0026#34;Time to convert image to json: %d ms\u0026#34;, (end2 - start2) / 1000000); LOGGER.debugf(\u0026#34;JSON Message with id %s\u0026#34;, jsonMessage); try { long start3 = System.nanoTime(); mqttPublisher.publish(jsonMessage); long end3 = System.nanoTime(); LOGGER.debugf(\u0026#34;Time to publish image: %d ms\u0026#34;, (end3 - start3) / 1000000); LOGGER.debugf(\u0026#34;Message with id %s published to topic: %s\u0026#34;, timestamp, topic); } catch (MqttException e) { e.printStackTrace(); } } if(saveImage){ String filepath = tmpFolder+\u0026#34;/\u0026#34; + timestamp + \u0026#34;.jpg\u0026#34;; imageService.saveImageAsync(frame, filepath).thenAccept(success -\u0026gt; { if (success) { LOGGER.debug(\u0026#34;Frame saved successfully\u0026#34;); } else { LOGGER.error(\u0026#34;Failed to save frame\u0026#34;); } }); } } count++; if (stopRequested) { // Check if stop has been requested inside the inner loop as well break; } } capture.set(Videoio.CAP_PROP_POS_FRAMES, 0); // Reset the video to the first frame } capture.release(); } // Capture and save a defined number of images every second void captureAndSaveImage() { LOGGER.debugf(\u0026#34;The Thread name is %s\u0026#34; + Thread.currentThread().getName()); // Capture the image long start = System.nanoTime(); Mat image = imageCaptureService.captureImage(this.camera); long end = System.nanoTime(); LOGGER.debugf(\u0026#34;Time to capture image: %d ms\u0026#34;, (end - start) / 1000000); // Publish the image to the MQTT broker long timestamp = System.currentTimeMillis(); if(util != null) { long start2 = System.nanoTime(); String jsonMessage = util.matToJson(image, timestamp); long end2 = System.nanoTime(); LOGGER.debugf(\u0026#34;Time to convert image to json: %d ms\u0026#34;, (end2 - start2) / 1000000); LOGGER.debugf(\u0026#34;JSON Message with id %s\u0026#34;, jsonMessage); try { long start3 = System.nanoTime(); mqttPublisher.publish(jsonMessage); // Check if stop has been requested if (stopRequested) { // Stop capture and release camera vertx.cancelTimer(timerId); timerId = null; imageCaptureService.releaseCamera(this.camera); mqttPublisher.disconnect(); LOGGER.info(\u0026#34;Capture stopped\u0026#34;); return; } long end3 = System.nanoTime(); LOGGER.debugf(\u0026#34;Time to publish image: %d ms\u0026#34;, (end3 - start3) / 1000000); LOGGER.debugf(\u0026#34;Message with id %s published to topic: %s\u0026#34;, timestamp, topic); } catch (MqttException e) { e.printStackTrace(); } } // Save the image to the file system (asynchronously) if(saveImage){ String filepath = tmpFolder+\u0026#34;/\u0026#34; + timestamp + \u0026#34;.jpg\u0026#34;; imageService.saveImageAsync(image, filepath).thenAccept(success -\u0026gt; { if (success) { LOGGER.debug(\u0026#34;Image saved successfully\u0026#34;); } else { LOGGER.error(\u0026#34;Failed to save image\u0026#34;); } }); } } @POST @Path(\u0026#34;/start\u0026#34;) public Response start() { LOGGER.info(\u0026#34;Capture started\u0026#34;); stopRequested = false; mqttPublisher.connect(); //captureEnabled = true; if (timerId != null) { return Response.status(Response.Status.BAD_REQUEST).entity(\u0026#34;Capture is already running\u0026#34;).build(); } timerId = vertx.setPeriodic(periodicCapture, id -\u0026gt; captureAndSaveImage()); return Response.ok(\u0026#34;Capture started\u0026#34;).build(); } @POST @Path(\u0026#34;/test\u0026#34;) public Response test() { LOGGER.info(\u0026#34;Test started\u0026#34;); stopRequested = false; mqttPublisher.connect(); if (timerId != null) { return Response.status(Response.Status.BAD_REQUEST).entity(\u0026#34;Capture is already running\u0026#34;).build(); } testThread = new Thread(() -\u0026gt; readVideo(videoPath)); testThread.start(); return Response.ok(\u0026#34;read video from file started\u0026#34;).build(); } @POST @Path(\u0026#34;/stop\u0026#34;) public Response stop() { stopRequested = true; LOGGER.info(\u0026#34;Stop requested\u0026#34;); if (testThread != null) { try { testThread.join(); // Wait for the testThread to finish } catch (InterruptedException e) { Thread.currentThread().interrupt(); // Restore interrupted status } testThread = null; } return Response.ok(\u0026#34;Stop requested\u0026#34;).build(); } } The application.properties file should look like this:\n%dev.quarkus.http.port=8082 %dev.capture.mock=true %dev.catpure.videoPath=/projects/rivieradev-app/capture-app/src/main/resources/videos/track-christmas-tree.avi %dev.catpure.videoPeriodicCapture=30 quarkus.kafka.devservices.enabled=false quarkus.swagger-ui.always-include=true capture.videoDeviceIndex=${VIDE0_DEVICE_INDEX:0} capture.dropbox.token=${DROPBOX_TOKEN:null} capture.tmpFolder=${TMP_FOLDER:/Users/mouchan/crazy-train-images} capture.interval=${INTERVAL:100} capture.periodicCapture=${PERIODIC_CAPTURE:30} capture.brokerMqtt=${MQTT_BROKER:tcp://localhost:1883} capture.topic=${MQTT_TOPIC:train-image} capture.videoPath=${VIDEO_PATH:/projects/rivieradev-app/capture-app/src/main/resources/videos/track-christmas-tree.avi} capture.videoPeriodicCapture=${VIDEO_PERIODIC_CAPTURE:30} capture.saveImage=${SAVE_IMAGE:false} capture.mock=${MOCK:false} quarkus.log.level=${LOGGER_LEVEL:INFO} Compiling the project Before committing your changes, you need to build the project to ensure that there are no compilation errors.\nOpen a new terminal Run the command below cd capture-app mvn clean package Check that there are no errors and move on to the next section.\n"
},
{
	"uri": "http://localhost:1313/development/",
	"title": "Développement (30min)",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/overview/organization/",
	"title": "Organization",
	"tags": [],
	"description": "",
	"content": "TODO\n"
},
{
	"uri": "http://localhost:1313/overview/openshift/",
	"title": "OpenShift",
	"tags": [],
	"description": "",
	"content": "OpenShift cluster TODO\nOpenShift cluster details OCP Cluster console URL : https://console-openshift-console.apps.TODO\nOCP Cluster API URL : https://api.TODO:6443\nThere is a dedicated OpenShift user for each utilisateur. On your table you will find a poster with the relevant information.\nTo connect to your Openshift cluster, click on the OCP Cluster console URL above and fill in your username and password. You will have acces to the Web Terminal by clicking on the \u0026gt;_ icon on the top right. The Web Terminal provides the oc client.\n"
},
{
	"uri": "http://localhost:1313/development/intelligent-train/",
	"title": "Predict command",
	"tags": [],
	"description": "",
	"content": "In this section we will import the new model trained before.\nOpen a new terminal Run the commands below, replace user_id with your assigned user name: cd intelligent-train curl -o models/model.onnx http://minio.minio:9000/\u0026lt;user_id\u0026gt;/models/model.onnx If you have not finish the training of the model use the commands below,\ncd intelligent-train curl -o models/model.onnx http://minio.minio:9000/models/model.onnx "
},
{
	"uri": "http://localhost:1313/development/train-ceq-app/",
	"title": "Post process image",
	"tags": [],
	"description": "",
	"content": "train-ceq-app is an application based on Apache Camel, a Java library for implementing application integrations using Enterprise Integration Patterns (EIP). This application is mainly composed of Camel routes defined in the PostProcessingRoute.xml file. These routes define how messages are consumed, transformed and forwarded to other services or destinations.\nThe postproscessing-route performs the following operations:\nMessage consumption: The route first consumes messages from the MQTT broker using the paho:{{train.mqtt.source.topicName}}?brokerUrl={{train.mqtt.brokerUrl}} URI. The messages consumed are then recorded in the log.\nSaving the initial message: The initial message is saved in the message header under the name \u0026ldquo;origin\u0026rdquo; so that it can be retrieved later.\nExtract Message ID: The message ID is extracted using the JSONPath expression $.id and stored in the message header.\nMessage deserialization: The message is deserialized into a Java object of type org.redhat.demo.crazytrain.model.Result using the Jackson library.\nMessage processing: The message is then processed by the CommandProcessor.\nPublish the message: The processed message is published on another MQTT topic using the URI paho:{{command.mqtt.destination.topicName}}?brokerUrl={{train.mqtt.brokerUrl}}.\nRetrieving the initial message: The initial message saved in the header is retrieved and put back in the message body.\nCloud Event Generation: A cloud event is generated from the initial message and processed by the CloudEventProcessor.\nCloud Event Publication: The cloud event is published on a Kafka topic using the URI kafka:{{monitoring.kafka.destination.topicName}}?brokers={{train.kafka.brokerUrl}}.\nThe command-capture-image route works in a similar way, but consumes messages from a Kafka topic, extracts a command from the message, and sends an HTTP POST request to a specified URL with the command as a parameter.\nIn a camel route the data is continuously transformed by various actions. Sometimes it is necessary to perform a check on the original message and not on the transformed message. It is good practice to save the original message so that it can be retrieved later. With Camel this is done via the properties of the message header.\nIn the train-ceq-app project, you are going to modify the PostProcessingRoute.xml file to save the initial message so that you can retrieve it later.\nOpen the file src/main/resources/camel/PostProcessingRoute.xml. Add the following instruction at the line \u0026lt;!-- add setHeader here --\u0026gt; : \u0026lt;setHeader name=\u0026#34;origin\u0026#34;\u0026gt;\u0026lt;simple\u0026gt;${body}\u0026lt;/simple\u0026gt;\u0026lt;/setHeader\u0026gt; This instruction saves the initial message in the message header under the name \u0026ldquo;origin\u0026rdquo;.\nNext, add the following statement at the line \u0026lt;!-- add setBody here --\u0026gt; : \u0026lt;setBody\u0026gt;\u0026lt;simple\u0026gt;${header.origin}\u0026lt;/simple\u0026gt;\u0026lt;/setBody\u0026gt; This instruction retrieves the original message saved in the header and puts it back in the message body.\nSave your changes. Now the src/main/resources/PostProcessingRoute.xml route saves the original message and retrieves it later. This allows you to check the original message and not the transformed message.\nThis is what the route should look like after your changes:\n\u0026lt;routes xmlns=\u0026#34;http://camel.apache.org/schema/spring\u0026#34;\u0026gt; \u0026lt;route id=\u0026#34;postproscesing-route\u0026#34;\u0026gt; \u0026lt;from uri=\u0026#34;paho:{{train.mqtt.source.topicName}}?brokerUrl={{train.mqtt.brokerUrl}}\u0026#34;/\u0026gt; \u0026lt;log loggingLevel=\u0026#34;DEBUG\u0026#34; message=\u0026#34;MQTT message received:\u0026#34;/\u0026gt; \u0026lt;log loggingLevel=\u0026#34;DEBUG\u0026#34; message=\u0026#34;${body}\u0026#34;/\u0026gt; \u0026lt;setHeader name=\u0026#34;origin\u0026#34;\u0026gt;\u0026lt;simple\u0026gt;${body}\u0026lt;/simple\u0026gt;\u0026lt;/setHeader\u0026gt; \u0026lt;setHeader name=\u0026#34;id\u0026#34;\u0026gt;\u0026lt;jsonpath\u0026gt;$.id\u0026lt;/jsonpath\u0026gt;\u0026lt;/setHeader\u0026gt; \u0026lt;log message=\u0026#34;Id of the message: ${header.id}\u0026#34;/\u0026gt; \u0026lt;unmarshal\u0026gt; \u0026lt;json library=\u0026#34;Jackson\u0026#34; unmarshalType=\u0026#34;org.redhat.demo.crazytrain.model.Result\u0026#34;/\u0026gt;\u0026lt;/unmarshal\u0026gt; \u0026lt;log message=\u0026#34;unmarshalling done\u0026#34;/\u0026gt; \u0026lt;process ref=\u0026#34;CommandProcessor\u0026#34;/\u0026gt; \u0026lt;log message=\u0026#34;Train Command: ${body}\u0026#34;/\u0026gt; \u0026lt;toD uri=\u0026#34;paho:{{command.mqtt.destination.topicName}}?brokerUrl={{train.mqtt.brokerUrl}}\u0026#34;/\u0026gt; \u0026lt;setBody\u0026gt;\u0026lt;simple\u0026gt;${header.origin}\u0026lt;/simple\u0026gt;\u0026lt;/setBody\u0026gt; \u0026lt;convertBodyTo type=\u0026#34;java.lang.String\u0026#34;/\u0026gt; \u0026lt;log loggingLevel=\u0026#34;DEBUG\u0026#34; message=\u0026#34;generating cloud event ${body}\u0026#34;/\u0026gt; \u0026lt;process ref=\u0026#34;CloudEventProcessor\u0026#34;/\u0026gt; \u0026lt;log loggingLevel=\u0026#34;DEBUG\u0026#34; message=\u0026#34;${body}\u0026#34;/\u0026gt; \u0026lt;toD uri=\u0026#34;kafka:{{monitoring.kafka.destination.topicName}}?brokers={{train.kafka.brokerUrl}}\u0026#34;/\u0026gt; \u0026lt;log loggingLevel=\u0026#34;DEBUG\u0026#34; message=\u0026#34;written into kafka\u0026#34;/\u0026gt; \u0026lt;/route\u0026gt; \u0026lt;route id=\u0026#34;command-capture-image\u0026#34;\u0026gt; \u0026lt;from uri=\u0026#34;kafka:{{monitoring.kafka.source.topicName}}?brokers={{train.kafka.brokerUrl}}\u0026#34;/\u0026gt; \u0026lt;setHeader name=\u0026#34;command\u0026#34;\u0026gt;\u0026lt;jsonpath\u0026gt;$.command\u0026lt;/jsonpath\u0026gt;\u0026lt;/setHeader\u0026gt; \u0026lt;toD uri=\u0026#34;{{train.http.url}}/${header.command}?httpMethod=POST\u0026#34; /\u0026gt; \u0026lt;/route\u0026gt; Compiling the project Before committing your changes, you need to build the project to ensure that there are no compilation errors.\nOpen a new terminal Run the command below mvn clean package "
},
{
	"uri": "http://localhost:1313/development/monitoring-app/",
	"title": "Monitoring",
	"tags": [],
	"description": "",
	"content": "The monitoring-app is an application which monitors the status and behaviour of the train and its associated components. This microservice is responsible for :\nData collection: The monitoring-appp application collects data from a kafka topic. This includes events produced by train-ceq-app.\nData analysis: Once the data has been collected, the monitoring-appp application adds the predictions calculated above to the original image.\nData visualisation: The monitoring-appp application provides a user interface for viewing train data in real time.\nIn the monitoring-app project, you will modify certain properties and the code with the following instructions:\nModify the configuration file: Open the configuration file for your application. This is the file named src/main/resources/application.properties. Add the following properties: mp.messaging.incoming.train-monitoring.connector=smallrye-kafka mp.messaging.incoming.train-monitoring.topic=${KAFKA_TOPIC_MONITORING_NAME:train-monitoring} mp.messaging.incoming.train-monitoring.cloud-events=false mp.messaging.incoming.train-monitoring.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer These properties configure the application to use the SmallRye Kafka connector to read messages from the Kafka train-monitoring topic. The deserializer is configured to convert the Kafka messages, which are bytes, into character strings.\n**Modify the ImageProcessing class: Open the file src/main/java/org/redhat/demo/crazytrain/processing/ImageProcessing.java. Add the @Incoming(\u0026quot;train-monitoring\u0026quot;) annotation to the process method. Below is the result:\n@Incoming(\u0026#34;train-monitoring\u0026#34;) public void process(String message) { // existing code } The @Incoming annotation indicates that this method should be called whenever a message is read from the train-monitoring channel. The message is passed to the method as a parameter.\nThese modifications allow our application to consume messages from the Kafka train-monitoring topic and process them with the process method of the ImageProcessing class.\nChecking the code The src/main/java/org/redhat/demo/crazytrain/processing/ImageProcessing.java class should look like this:\npackage org.redhat.demo.crazytrain.processing; import java.util.Base64; import java.util.concurrent.TimeUnit; import org.eclipse.microprofile.reactive.messaging.Incoming; import jakarta.ws.rs.core.MediaType; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.annotation.PostConstruct; import jakarta.inject.Inject; import org.eclipse.microprofile.config.inject.ConfigProperty; import org.jboss.logging.Logger; import org.opencv.core.CvType; import org.opencv.core.Mat; import org.redhat.demo.crazytrain.services.SaveService; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.JsonMappingException; import com.fasterxml.jackson.databind.JsonNode; import com.fasterxml.jackson.databind.ObjectMapper; import io.micrometer.core.instrument.MeterRegistry; import io.micrometer.core.instrument.Timer; import io.smallrye.mutiny.Multi; import io.smallrye.mutiny.operators.multi.processors.BroadcastProcessor; @Path(\u0026#34;/train-monitoring\u0026#34;) public class ImageProcessing { private static final Logger LOGGER = Logger.getLogger(ImageProcessing.class); private final BroadcastProcessor\u0026lt;String\u0026gt; broadcastProcessor = BroadcastProcessor.create(); @Inject SaveService saveService; @ConfigProperty(name = \u0026#34;monitoring.saveImage\u0026#34;) boolean saveImage; @ConfigProperty(name = \u0026#34;monitoring.tmpFolder\u0026#34;) String tmpFolder; @Inject MeterRegistry registry; Timer timer; @PostConstruct void init() { timer = Timer.builder(\u0026#34;image.processing.time\u0026#34;) .description(\u0026#34;Time taken to get a message from Kafka and process it\u0026#34;) .register(registry); } @Incoming(\u0026#34;train-monitoring\u0026#34;) public void process(String result) { LOGGER.debug(\u0026#34;Consumer kafka recived : \u0026#34;+result); long start = System.nanoTime(); ObjectMapper mapper = new ObjectMapper(); JsonNode jsonNode; try { jsonNode = mapper.readTree(result); JsonNode data = jsonNode.get(\u0026#34;data\u0026#34;); String imageBytesBase64 = data.get(\u0026#34;image\u0026#34;).asText(); broadcastProcessor.onNext(imageBytesBase64); long end = System.nanoTime(); timer.record(end - start, TimeUnit.NANOSECONDS); } catch (JsonMappingException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (JsonProcessingException e) { // TODO Auto-generated catch block e.printStackTrace(); } } @GET @Produces(MediaType.SERVER_SENT_EVENTS) public Multi\u0026lt;String\u0026gt; stream() { return broadcastProcessor.toHotStream(); } } The application.properties file should look like :\n%dev.quarkus.http.port=8086 # Configure the Kafka source kafka.bootstrap.servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092} mp.messaging.incoming.train-monitoring.connector=smallrye-kafka mp.messaging.incoming.train-monitoring.topic=${KAFKA_TOPIC_MONITORING_NAME:train-monitoring} mp.messaging.incoming.train-monitoring.cloud-events=false mp.messaging.incoming.train-monitoring.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer mp.messaging.outgoing.commands-out.connector=smallrye-kafka mp.messaging.outgoing.commands-out.topic=${KAFKA_TOPIC_COMMAND_CAPTURE_NAME:train-command-capture} mp.messaging.outgoing.commands-out.value.serializer=org.apache.kafka.common.serialization.StringSerializer monitoring.saveImage=${SAVE_IMAGE:false} monitoring.tmpFolder=${TMP_FOLDER:/tmp/crazy-train-images} quarkus.log.level=${LOGGER_LEVEL:INFO} quarkus.swagger-ui.always-include=true %dev.kafka.topic.train-command-capture.replication.factor=1 %dev.kafka.topic.train-monitoring.replication.factor=1 Compiling the project Before committing your changes, you need to build the project to ensure that there are no compilation errors.\nOpen a new terminal Run the command below ./mvnw clean package "
},
{
	"uri": "http://localhost:1313/development/start-services/",
	"title": "Start services",
	"tags": [],
	"description": "",
	"content": " From Devspaces, click on the search bar on the top and choose \u0026ldquo;Run Task\u0026rdquo; from the drop-down list. ! Run Task menu\nSelect the start-all-apps task, this task will run all the previously modified applications in parallel.\nClick on Continue without scanning the task outoput. Each application will start in a terminal. Terminals are accessible from the bottom right, Select \u0026rsquo;no\u0026rsquo; on the pop-up which indicates that a new process has started and that it is possible to make a port redirection.\nTo check that all the applications have started, you should have the following logs: Log capture-app intelligent-train log**! Log intelligent-train application](/images/dev-section/intelligent-train-log.png)\nLog train-ceq-app Train-ceq-app log (/images/dev-section/train-ceq-log.png)\nMonitoring-app log**! Log train-controller Now that all the applications have been started, we\u0026rsquo;re going to simulate the operation of our intelligent train!\n"
},
{
	"uri": "http://localhost:1313/development/test-services/",
	"title": "Test services",
	"tags": [],
	"description": "",
	"content": "We are going to simulate the operation of the train:\nOpen a new terminal Execute the command below to retrieve the URL of the monitoring console: oc get routes -o jsonpath=\u0026#39;{range .items[*]}{.metadata.annotations.che\\.routing\\.controller\\.devfile\\.io/endpoint-name}{\u0026#34;\\t\u0026#34;}{.spec.host}{\u0026#34;\\n\u0026#34;}{end}\u0026#39; | grep monitoring-svc | cut -f 2 Copy the URL, launch a new browser window in anonymous mode (in order to have an empty cache), insert the URL. Return to your terminal and run the following command: curl -X \u0026#39;POST\u0026#39; \u0026#39;http://localhost:8082/capture/test\u0026#39; -H \u0026#39;accept: */*\u0026#39; From your browser, you should be able to see the train simulation and the traffic sign detection in real time Well done! The simulation worked well :) now you can stop the simulation by closing all the terminals.\n"
},
{
	"uri": "http://localhost:1313/development/conclusion/",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "Congratulations, you\u0026rsquo;ve finished the development section! You should now have a better understanding of the Crazy Train application and its microservices-based architecture. The lab isn\u0026rsquo;t over yet! In the next section, we\u0026rsquo;re going to find out how to deploy our applications using gitops tools.\n"
},
{
	"uri": "http://localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/",
	"title": "Welcome",
	"tags": [],
	"description": "",
	"content": "Riviera Dev 2024 - Lab \u0026ldquo;Crazy Train\u0026rdquo; Welcome, dear Red Hatter, in this Lab where you will discover a part of the Red Hat offering related to Edge Computing and AI.\nYou will play with the following technologies:\nTODO In this lab, you will TODO\nFun are expected ahead!\n"
}]